{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca = 2.5\n",
      "cb = 0.5\n",
      "cd = 2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "a = [1., 2.]\n",
    "b = [2., 4.]\n",
    "c = [2.5, 4.]\n",
    "d = [4.5, 5.]\n",
    "\n",
    "# euclidean distance\n",
    "ca = spatial.distance.euclidean(c, a)\n",
    "cb = spatial.distance.euclidean(c, b)\n",
    "cd = spatial.distance.euclidean(c, d)\n",
    "\n",
    "print(\"ca = \" + str(ca))\n",
    "print(\"cb = \" + str(cb))\n",
    "print(\"cd = \" + str(cd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dists:\n",
      "ca = 0.004504527406047898\n",
      "cb = 0.004504527406047898\n",
      "cd = 0.015137225946083022\n",
      "ab = 0.0\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "# cosine distance using 1- Sc(A,B) = cos(theta)\n",
    "ca_dist = spatial.distance.cosine(c, a)\n",
    "cb_dist = spatial.distance.cosine(c, b)\n",
    "cd_dist = spatial.distance.cosine(c, d)\n",
    "ab_dist = spatial.distance.cosine(a, b)\n",
    "print(\"cosine dists:\")\n",
    "print(\"ca = \" + str(ca_dist))\n",
    "print(\"cb = \" + str(cb_dist))\n",
    "print(\"cd = \" + str(cd_dist))\n",
    "print(\"ab = \" + str(ab_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset \n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# load the movie lense dataset \n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9388  0.9335  0.9422  0.9266  0.9396  0.9361  0.0055  \n",
      "MAE (testset)     0.7380  0.7373  0.7440  0.7321  0.7383  0.7379  0.0038  \n",
      "Fit time          0.55    0.59    0.57    0.57    0.57    0.57    0.01    \n",
      "Test time         0.09    0.09    0.09    0.09    0.11    0.09    0.01    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.93875732, 0.93347213, 0.94219172, 0.92657735, 0.93958452]),\n",
       " 'test_mae': array([0.73798887, 0.73729206, 0.74404991, 0.7320549 , 0.73832417]),\n",
       " 'fit_time': (0.5500338077545166,\n",
       "  0.5883688926696777,\n",
       "  0.572803258895874,\n",
       "  0.5700273513793945,\n",
       "  0.5689244270324707),\n",
       " 'test_time': (0.08746910095214844,\n",
       "  0.08813977241516113,\n",
       "  0.08902573585510254,\n",
       "  0.08841609954833984,\n",
       "  0.1124715805053711)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the svd algorithm for reducing dimensionality of the data\n",
    "algo = SVD()\n",
    "\n",
    "# run 5-fold cross validation\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x7fb4dc097ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset module is used to load data from files,\n",
    "# into Pandas data frames, and built in datasets\n",
    "Dataset.load_builtin()\n",
    "# Dataset.load_from_file()\n",
    "# Dataset.load_from_df()\n",
    "\n",
    "# Reader class is used to parse a file containing ratings\n",
    "# Default format - each rating stored in separate line in the order\n",
    "# 'user', 'item', 'rating'. Order and separator configuration using params\n",
    "# 1. line_format - string that stores the order of the data with field names \n",
    "#     eg. \"item user rating\"\n",
    "# 2. sep - separator between fields such as ','\n",
    "# 3. rating_scale - specify rating sscale - default = (1,5)\n",
    "# 4. skip_lines - indicate number of lines to skip at beginning of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item user  rating\n",
      "0     1    A     1.0\n",
      "1     2    A     2.0\n",
      "2     1    B     2.0\n",
      "3     2    B     4.0\n",
      "4     1    C     2.5\n",
      "5     2    C     4.0\n",
      "6     1    D     4.5\n",
      "7     2    D     5.0\n",
      "8     1    E     3.0\n",
      "<surprise.reader.Reader object at 0x7fb518580eb0>\n",
      "<surprise.dataset.DatasetAutoFolds object at 0x7fb51dfef700>\n",
      "<surprise.dataset.DatasetAutoFolds object at 0x7fb4dc0a5fa0>\n"
     ]
    }
   ],
   "source": [
    "# load_data.py\n",
    "\n",
    "import pandas as pd\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "# One new user \"E\" who's rated only 1 movie\n",
    "ratings_dict = {\n",
    "    \"item\": [1, 2, 1, 2, 1, 2, 1, 2, 1],\n",
    "    \"user\": ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D', 'E'],\n",
    "    \"rating\": [1, 2, 2, 4, 2.5, 4, 4.5, 5, 3],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "print(df)\n",
    "print(reader)\n",
    "\n",
    "# load pandas data frame into Surpise dataset\n",
    "data = Dataset.load_from_df(df[[\"user\", \"item\", \"rating\"]], reader)\n",
    "print(data)\n",
    "\n",
    "# load builtin MovieLense-100k data set\n",
    "movieLens = Dataset.load_builtin('ml-100k')\n",
    "print(movieLens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<surprise.prediction_algorithms.knns.KNNWithMeans object at 0x7fb4dc0a5b20>\n"
     ]
    }
   ],
   "source": [
    "# recommender.py\n",
    "\n",
    "# KNN With Means = centered cos algo\n",
    "# name - similartiy metric to use (cosine, msd, pearson, pearson_baseline)\n",
    "# user_based - boolean for user based or item based\n",
    "# min_support - min number of common items needed btwn users to consider similarity\n",
    "from surprise import KNNWithMeans\n",
    "\n",
    "# item-based cosine similarity\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": False # comput item similarity\n",
    "}\n",
    "algo = KNNWithMeans(sim_options=sim_options)\n",
    "print(algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x7fb4dc0a5b20>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to train use N-fold\n",
    "# MovieLens 100K data uses 5 splits (5-fold cross-validation)\n",
    "# u1.base, u1.test, u2.base, u2.test...u5.base, u5.test\n",
    "# from load_data import data - load_data from code above\n",
    "# from recommender import  algo - recommender from python file above\n",
    "\n",
    "trainingSet = data.build_full_trainset()\n",
    "algo.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict what user E would rate the movie '2'\n",
    "prediction = algo.predict('E', 2)\n",
    "prediction.est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Tuning the Algo Params\n",
    "# GridSearchCV tries combos of params and reports the best params for accuracy\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "sim_options = {\n",
    "    \"name\": [\"msd\", \"cosine\"],\n",
    "    \"min_support\": [3, 4, 5],\n",
    "    \"user_based\": [False, True]\n",
    "}\n",
    "\n",
    "param_grid = {\"sim_options\": sim_options}\n",
    "gs = GridSearchCV(KNNWithMeans, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9442179979419243\n",
      "{'sim_options': {'name': 'msd', 'min_support': 3, 'user_based': False}}\n",
      "0.7407435682907325\n",
      "{'sim_options': {'name': 'msd', 'min_support': 3, 'user_based': False}}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])\n",
    "\n",
    "print(gs.best_score[\"mae\"])\n",
    "print(gs.best_params[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means that our Centered KNN Algo works best with\n",
    "# 1. Item based\n",
    "# 2. MSD similartiy metric\n",
    "# 3. Min support of 3\n",
    "\n",
    "# Model-based approaches, we can use Surprise to check which values work best\n",
    "# 1used in statistics to . n_epochs - number of iterations of SGD, an iterative method\n",
    "# 2. lr_all - learning rate for all params, param that decides how much params are adjusted\n",
    "# 3. reg_all - regularization term for all params, penalty term to prevent overfitting\n",
    "#NOTE: No similarity metrics in matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best values for SVD algorithm - Singular Value Decomposition\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "data = Dataset.load_builtin(\"ml-100k\")\n",
    "param_grid = {\n",
    "    \"n_epochs\": [5, 10],\n",
    "    \"lr_all\": [0.002, 0.005],\n",
    "    \"reg_all\": [0.4, 0.6]\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "gs.fit(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9640578222001827\n",
      "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n",
      "0.7725480658363456\n",
      "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}\n"
     ]
    }
   ],
   "source": [
    "# SVD outputs for rmse/mae for the GridSearchCV class\n",
    "# SVD algo is best for RMSE with below params\n",
    "print(gs.best_score[\"rmse\"])\n",
    "print(gs.best_params[\"rmse\"])\n",
    "\n",
    "print(gs.best_score[\"mae\"])\n",
    "print(gs.best_params[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
